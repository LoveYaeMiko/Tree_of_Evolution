#!/usr/bin/env python3
"""
èµ„æºæ£€æŸ¥è„šæœ¬
ç”¨äºæ£€æµ‹æ•°æ®é›†å’Œæ¨¡å‹æ˜¯å¦ä¸‹è½½å®Œæˆ
"""

import os
import json
from pathlib import Path
import torch
from transformers import AutoTokenizer, AutoModel, AutoModelForCausalLM
from datasets import load_dataset, get_dataset_config_names
import sys

class ResourceChecker:
    def __init__(self, base_dir="./resources"):
        self.base_dir = Path(base_dir)
        self.resources_status = {}
        
    def check_all_resources(self):
        """æ£€æŸ¥æ‰€æœ‰èµ„æº"""
        print("ğŸ” å¼€å§‹æ£€æŸ¥èµ„æºçŠ¶æ€...")
        print("=" * 60)
        
        self.check_stack_v1()
        self.check_benchmarks()
        self.check_models()
        self.check_training_data()
        
        self.print_summary()
        return self.all_resources_available()
    
    def check_stack_v1(self):
        """æ£€æŸ¥Stack v1æ•°æ®é›†"""
        print("\nğŸ“š æ£€æŸ¥Stack v1æ•°æ®é›†...")
        stack_dir = self.base_dir / "stack_v1"
        seed_file = stack_dir / "seed_samples.json"
        
        if seed_file.exists():
            try:
                with open(seed_file, 'r') as f:
                    data = json.load(f)
                status = f"âœ“ å·²ä¸‹è½½ ({len(data)} ä¸ªæ ·æœ¬)"
                self.resources_status["stack_v1"] = True
            except Exception as e:
                status = f"âœ— æ–‡ä»¶æŸå: {e}"
                self.resources_status["stack_v1"] = False
        else:
            status = "âœ— æœªæ‰¾åˆ°"
            self.resources_status["stack_v1"] = False
        
        print(f"  Stack v1ç§å­æ•°æ®: {status}")
    
    def check_benchmarks(self):
        """æ£€æŸ¥åŸºå‡†æ•°æ®é›†"""
        print("\nğŸ† æ£€æŸ¥åŸºå‡†æ•°æ®é›†...")
        
        benchmarks = [
            ("HumanEval", "humaneval"),
            ("MBPP", "mbpp")
        ]
        
        for name, dataset_dir in benchmarks:
            benchmark_path = self.base_dir / "benchmarks" / dataset_dir
            
            # æ£€æŸ¥æœ¬åœ°ä¿å­˜çš„æ•°æ®é›†
            if benchmark_path.exists():
                try:
                    # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®é›†æ–‡ä»¶
                    dataset_files = list(benchmark_path.glob("*"))
                    if dataset_files:
                        # å°è¯•åŠ è½½JSONæµ‹è¯•æ•°æ®
                        test_file = self.base_dir / "benchmarks" / f"{dataset_dir}_test.json"
                        if test_file.exists():
                            with open(test_file, 'r') as f:
                                test_data = json.load(f)
                            status = f"âœ“ å·²ä¸‹è½½ ({len(test_data)} ä¸ªæ ·æœ¬)"
                        else:
                            status = "âœ“ å·²ä¸‹è½½"
                        self.resources_status[f"benchmark_{dataset_dir}"] = True
                    else:
                        status = "âœ— ç›®å½•ä¸ºç©º"
                        self.resources_status[f"benchmark_{dataset_dir}"] = False
                except Exception as e:
                    status = f"âœ— åŠ è½½å¤±è´¥: {str(e)[:50]}..."
                    self.resources_status[f"benchmark_{dataset_dir}"] = False
            else:
                status = "âœ— æœªæ‰¾åˆ°"
                self.resources_status[f"benchmark_{dataset_dir}"] = False
            
            print(f"  {name}: {status}")
    
    def check_models(self):
        """æ£€æŸ¥æ¨¡å‹"""
        print("\nğŸ¤– æ£€æŸ¥æ¨¡å‹...")
        
        models_to_check = {
            "qwen2.5-coder-1.5b": "Qwen/Qwen2.5-Coder-1.5B",
            "qwen2.5-coder-7b": "Qwen/Qwen2.5-Coder-7B",
            "gte-large": "thenlper/gte-large"
        }
        
        for model_name, model_id in models_to_check.items():
            model_dir = self.base_dir / "models" / model_name
            
            if model_dir.exists():
                try:
                    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
                    model_files = list(model_dir.glob("*"))
                    essential_files = [
                        "config.json",
                        "pytorch_model.bin",
                        "model.safetensors",
                        "tokenizer.json",
                        "vocab.json"
                    ]
                    
                    # æ£€æŸ¥æ˜¯å¦æœ‰è‡³å°‘ä¸€äº›å…³é”®æ–‡ä»¶
                    has_essential = any((model_dir / f).exists() for f in essential_files[:3])
                    
                    if has_essential and len(model_files) >= 3:
                        status = f"âœ“ å·²ä¸‹è½½ ({len(model_files)} ä¸ªæ–‡ä»¶)"
                        self.resources_status[f"model_{model_name}"] = True
                    else:
                        status = "âœ— æ–‡ä»¶ä¸å®Œæ•´"
                        self.resources_status[f"model_{model_name}"] = False
                except Exception as e:
                    status = f"âœ— æ£€æŸ¥å¤±è´¥: {str(e)[:30]}..."
                    self.resources_status[f"model_{model_name}"] = False
            else:
                status = "âœ— æœªæ‰¾åˆ°"
                self.resources_status[f"model_{model_name}"] = False
            
            print(f"  {model_name}: {status}")
    
    def check_training_data(self):
        """æ£€æŸ¥è®­ç»ƒæ•°æ®"""
        print("\nğŸ“Š æ£€æŸ¥è®­ç»ƒæ•°æ®...")
        
        training_data_paths = {
            "åˆæˆæ•°æ®": self.base_dir.parent / "results" / "synthesized_data" / "training_data.json",
            "é«˜è´¨é‡æ•°æ®": self.base_dir.parent / "results" / "synthesized_data" / "instruction_response_pairs_high_quality.json"
        }
        
        for name, path in training_data_paths.items():
            if path.exists():
                try:
                    with open(path, 'r') as f:
                        data = json.load(f)
                    status = f"âœ“ å·²ç”Ÿæˆ ({len(data)} ä¸ªæ ·æœ¬)"
                    self.resources_status[f"training_{name}"] = True
                except Exception as e:
                    status = f"âœ— æ–‡ä»¶æŸå: {e}"
                    self.resources_status[f"training_{name}"] = False
            else:
                status = "âœ— æœªæ‰¾åˆ°"
                self.resources_status[f"training_{name}"] = False
            
            print(f"  {name}: {status}")
    
    def check_gpu_resources(self):
        """æ£€æŸ¥GPUèµ„æº"""
        print("\nğŸ’» æ£€æŸ¥GPUèµ„æº...")
        
        if torch.cuda.is_available():
            gpu_count = torch.cuda.device_count()
            print(f"  GPUå¯ç”¨: âœ“ ({gpu_count} ä¸ªGPU)")
            
            for i in range(gpu_count):
                gpu_name = torch.cuda.get_device_name(i)
                memory_total = torch.cuda.get_device_properties(i).total_memory / 1024**3
                memory_allocated = torch.cuda.memory_allocated(i) / 1024**3
                memory_reserved = torch.cuda.memory_reserved(i) / 1024**3
                
                print(f"    GPU {i}: {gpu_name}")
                print(f"      æ˜¾å­˜: {memory_total:.1f}GB (å·²åˆ†é…: {memory_allocated:.1f}GB, ä¿ç•™: {memory_reserved:.1f}GB)")
        else:
            print("  GPUå¯ç”¨: âœ— (å°†ä½¿ç”¨CPUï¼Œä½†æ€§èƒ½ä¼šå—å½±å“)")
    
    def check_disk_space(self):
        """æ£€æŸ¥ç£ç›˜ç©ºé—´"""
        print("\nğŸ’¾ æ£€æŸ¥ç£ç›˜ç©ºé—´...")
        
        try:
            import shutil
            total, used, free = shutil.disk_usage("/")
            
            print(f"  æ€»ç©ºé—´: {total // (2**30):,} GB")
            print(f"  å·²ä½¿ç”¨: {used // (2**30):,} GB") 
            print(f"  å‰©ä½™ç©ºé—´: {free // (2**30):,} GB")
            
            if free < 50 * 1024**3:  # 50GB
                print("  âš  è­¦å‘Š: å‰©ä½™ç©ºé—´ä¸è¶³50GBï¼Œå¯èƒ½å½±å“è¿è¡Œ")
                return False
            return True
        except:
            print("  æ— æ³•è·å–ç£ç›˜ç©ºé—´ä¿¡æ¯")
            return True
    
    def print_summary(self):
        """æ‰“å°æ£€æŸ¥æ‘˜è¦"""
        print("\n" + "=" * 60)
        print("ğŸ“‹ èµ„æºæ£€æŸ¥æ‘˜è¦")
        print("=" * 60)
        
        available = sum(1 for status in self.resources_status.values() if status)
        total = len(self.resources_status)
        
        print(f"èµ„æºå®Œæˆåº¦: {available}/{total} ({available/total*100:.1f}%)")
        
        # æŒ‰ç±»åˆ«æ˜¾ç¤ºçŠ¶æ€
        categories = {
            "æ•°æ®é›†": [k for k in self.resources_status.keys() if k.startswith("benchmark") or k == "stack_v1"],
            "æ¨¡å‹": [k for k in self.resources_status.keys() if k.startswith("model")],
            "è®­ç»ƒæ•°æ®": [k for k in self.resources_status.keys() if k.startswith("training")]
        }
        
        for category, keys in categories.items():
            cat_available = sum(1 for k in keys if self.resources_status[k])
            cat_total = len(keys)
            status_icon = "âœ“" if cat_available == cat_total else "âš " if cat_available > 0 else "âœ—"
            print(f"  {category}: {status_icon} ({cat_available}/{cat_total})")
        
        # æ£€æŸ¥GPUå’Œç£ç›˜
        self.check_gpu_resources()
        disk_ok = self.check_disk_space()
        
        # æä¾›å»ºè®®
        print("\nğŸ’¡ å»ºè®®:")
        if available == total:
            print("  âœ… æ‰€æœ‰èµ„æºå·²å°±ç»ªï¼Œå¯ä»¥å¼€å§‹è¿è¡Œ!")
        else:
            missing = [k for k, v in self.resources_status.items() if not v]
            print(f"  âš  ç¼ºå°‘èµ„æº: {', '.join(missing)}")
            print("  è¯·è¿è¡Œ: python download_resources.py")
        
        if not torch.cuda.is_available():
            print("  âš  æ²¡æœ‰æ£€æµ‹åˆ°GPUï¼Œè®­ç»ƒå’Œæ¨ç†ä¼šå¾ˆæ…¢")
        
        if not disk_ok:
            print("  âš  ç£ç›˜ç©ºé—´ä¸è¶³ï¼Œè¯·æ¸…ç†ç©ºé—´")
    
    def all_resources_available(self):
        """æ£€æŸ¥æ˜¯å¦æ‰€æœ‰å¿…éœ€èµ„æºéƒ½å¯ç”¨"""
        # å¿…éœ€èµ„æºï¼šæ•°æ®é›†å’Œæ¨¡å‹
        required_keys = [k for k in self.resources_status.keys() 
                        if k.startswith("benchmark") or k.startswith("model") or k == "stack_v1"]
        
        return all(self.resources_status.get(k, False) for k in required_keys)
    
    def get_missing_resources(self):
        """è·å–ç¼ºå¤±çš„èµ„æºåˆ—è¡¨"""
        return [k for k, v in self.resources_status.items() if not v]

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="èµ„æºæ£€æŸ¥å·¥å…·")
    parser.add_argument("--base_dir", type=str, default="./resources",
                       help="èµ„æºåŸºç¡€ç›®å½•")
    parser.add_argument("--auto_download", action="store_true",
                       help="è‡ªåŠ¨ä¸‹è½½ç¼ºå¤±çš„èµ„æº")
    
    args = parser.parse_args()
    
    checker = ResourceChecker(args.base_dir)
    all_available = checker.check_all_resources()
    
    if not all_available and args.auto_download:
        print("\nğŸ”„ è‡ªåŠ¨ä¸‹è½½ç¼ºå¤±èµ„æº...")
        try:
            from download_resources import ResourceDownloader
            downloader = ResourceDownloader(args.base_dir)
            downloader.download_all()
            
            # é‡æ–°æ£€æŸ¥
            print("\nğŸ”„ é‡æ–°æ£€æŸ¥èµ„æºçŠ¶æ€...")
            checker = ResourceChecker(args.base_dir)
            checker.check_all_resources()
        except Exception as e:
            print(f"âŒ è‡ªåŠ¨ä¸‹è½½å¤±è´¥: {e}")
    
    # è¿”å›é€€å‡ºä»£ç 
    sys.exit(0 if all_available else 1)

if __name__ == "__main__":
    main()